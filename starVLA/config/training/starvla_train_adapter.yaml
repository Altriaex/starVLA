run_id: starvla
run_root_dir: path/to/result
seed: 42
trackers: [jsonl, wandb]
wandb_entity: your-wandb-entity
wandb_project: your-wandb-project
is_debug: false

framework:
  name: QwenAdapter
  qwenvl:
    base_vlm: ./playground/Pretrained_models/Qwen2.5-VL-3B-Instruct-Action
    attn_implementation: flash_attention_2
    vl_hidden_dim: 2048 # 2b while 2560 # fit qwen3-vl-4b
  dino:
    dino_backbone: dinov2_vits14
  action_model:
    action_model_type: VLA-Adapter
    hidden_dim: 2048 # fit for 2b 2560 # fit qwen3-vl-4b
    action_dim: 7 # libero specific action dim
    state_dim: 14 # no proprio for libero though
    action_query_num: 64
    use_pro_version: true  # use the pro version of MLPResNet
    use_proprio: false # no proprio for libero
    phase: Training
    num_actions_chunk: 8 # ! libero specific action chunk 
    future_action_window_size: 7 # ! not quite sure why this is num_actions_chunk -1
  reduce_in_full_precision: true


datasets:
  vla_data:
    dataset_py: lerobot_datasets
    data_root_dir: playground/Datasets/LEROBOT_LIBERO_DATA
    data_mix: libero_all # libero_goal
    action_type: delta_qpos
    CoT_prompt: "Your task is {instruction}. To identify the key objects for your task. Locate their bounding boxes in [x1,y1,x2,y2] format."
    CoT_answer: bbox
    default_image_resolution: [3, 224, 224]
    per_device_batch_size: 16
    load_all_data_for_training: true
    obs: ["image_0"]
    video_backend: torchvision_av


trainer:
  epochs: 100
  max_train_steps: 100000
  num_warmup_steps: 5000
  save_interval: 5000
  eval_interval: 100
  learning_rate:
    base: 2.0e-05  # Changed from 2.5e-05 (VLA-Adapter uses 2e-5)
    qwen_vl_interface: 2.0e-05  # Align with base lr (VLA-Adapter doesn't differentiate)
    action_model: 1.0e-04
  lr_scheduler_type: constant  # Changed from cosine_with_min_lr (VLA-Adapter uses "constant")
  scheduler_specific_kwargs:
    min_lr: 1.0e-06
  freeze_modules: ''
  loss_scale:
    vla: 1.0
    vlm: 1.0 # Increased from 0.1 to 1.0 for VLA-Adapter, for the action query learning
  max_grad_norm: 1.0
  warmup_ratio: 0.1
  weight_decay: 0.0
  logging_frequency: 10
  gradient_clipping: 1.0
  gradient_accumulation_steps: 1

  optimizer:
    name: AdamW
    betas: [0.9, 0.95]
    eps: 1.0e-08
    weight_decay: 1.0e-08

  # parameters to be determined
  is_resume: false
  resume_epoch: null
  resume_step: null
  enable_gradient_checkpointing: true
  enable_mixed_precision_training: true

